{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk #Natural Language Toolkit\n",
    "import mgzip\n",
    "import pickle\n",
    "import string\n",
    "import contractions\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from os.path import exists\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "################################## CONSTANTS ##################################\n",
    "\n",
    "# Train dataset from Kaggle\n",
    "DS_PATH = './data/goodreads_train.csv'\n",
    "\n",
    "# Path to save the dataset with the reviews already cleaned\n",
    "ZIP_PATH = './data/cleaned_ds.gz'\n",
    "\n",
    "PUNCT_TO_REMOVE = string.punctuation\n",
    "\n",
    "LANG = 'english'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "'Hi'"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Hi\"\n",
    "text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dalex\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "ss = SnowballStemmer(language=LANG)\n",
    "\n",
    "nltk.download('stopwords')\n",
    "all_stopwords = stopwords.words(LANG)\n",
    "all_stopwords.remove('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def cleanText(sentence):\n",
    "    # Lowercase the sentence\n",
    "    sentence = sentence.lower()\n",
    "    \n",
    "    # Remove links\n",
    "    sentence =  re.sub(r\"(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", sentence)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    sentence = sentence.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n",
    "    \n",
    "    # Remove numbers\n",
    "    sentence = ''.join([char for char in sentence if not char.isdigit()])\n",
    "    \n",
    "    # Remove emojis and emoticons\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    sentence = emoji_pattern.sub(r'', sentence)\n",
    "    \n",
    "    # Remove contractions\n",
    "    sentence = contractions.fix(sentence)\n",
    "    \n",
    "    # Stemming and remove stopwords and extra spaces\n",
    "    sentence = sentence.split()\n",
    "    sentence = [ss.stem(word) for word in sentence if not word in all_stopwords]\n",
    "    sentence = ' '.join(sentence)\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening original dataset\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/goodreads_train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [59], line 7\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[39melse\u001B[39;00m:\n\u001B[0;32m      6\u001B[0m     \u001B[39mprint\u001B[39m(\u001B[39m'\u001B[39m\u001B[39mOpening original dataset\u001B[39m\u001B[39m'\u001B[39m)\n\u001B[1;32m----> 7\u001B[0m     reviews_df \u001B[39m=\u001B[39m pd\u001B[39m.\u001B[39;49mread_csv(ds_path)\n\u001B[0;32m      8\u001B[0m     tqdm\u001B[39m.\u001B[39mpandas()\n\u001B[0;32m      9\u001B[0m     \u001B[39mprint\u001B[39m(\u001B[39m'\u001B[39m\u001B[39mCleaning rewiews\u001B[39m\u001B[39m'\u001B[39m)\n",
      "File \u001B[1;32mc:\\Users\\dalex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    305\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mlen\u001B[39m(args) \u001B[39m>\u001B[39m num_allow_args:\n\u001B[0;32m    306\u001B[0m     warnings\u001B[39m.\u001B[39mwarn(\n\u001B[0;32m    307\u001B[0m         msg\u001B[39m.\u001B[39mformat(arguments\u001B[39m=\u001B[39marguments),\n\u001B[0;32m    308\u001B[0m         \u001B[39mFutureWarning\u001B[39;00m,\n\u001B[0;32m    309\u001B[0m         stacklevel\u001B[39m=\u001B[39mstacklevel,\n\u001B[0;32m    310\u001B[0m     )\n\u001B[1;32m--> 311\u001B[0m \u001B[39mreturn\u001B[39;00m func(\u001B[39m*\u001B[39margs, \u001B[39m*\u001B[39m\u001B[39m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mc:\\Users\\dalex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:678\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[0;32m    663\u001B[0m kwds_defaults \u001B[39m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m    664\u001B[0m     dialect,\n\u001B[0;32m    665\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    674\u001B[0m     defaults\u001B[39m=\u001B[39m{\u001B[39m\"\u001B[39m\u001B[39mdelimiter\u001B[39m\u001B[39m\"\u001B[39m: \u001B[39m\"\u001B[39m\u001B[39m,\u001B[39m\u001B[39m\"\u001B[39m},\n\u001B[0;32m    675\u001B[0m )\n\u001B[0;32m    676\u001B[0m kwds\u001B[39m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m--> 678\u001B[0m \u001B[39mreturn\u001B[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001B[1;32mc:\\Users\\dalex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    572\u001B[0m _validate_names(kwds\u001B[39m.\u001B[39mget(\u001B[39m\"\u001B[39m\u001B[39mnames\u001B[39m\u001B[39m\"\u001B[39m, \u001B[39mNone\u001B[39;00m))\n\u001B[0;32m    574\u001B[0m \u001B[39m# Create the parser.\u001B[39;00m\n\u001B[1;32m--> 575\u001B[0m parser \u001B[39m=\u001B[39m TextFileReader(filepath_or_buffer, \u001B[39m*\u001B[39m\u001B[39m*\u001B[39mkwds)\n\u001B[0;32m    577\u001B[0m \u001B[39mif\u001B[39;00m chunksize \u001B[39mor\u001B[39;00m iterator:\n\u001B[0;32m    578\u001B[0m     \u001B[39mreturn\u001B[39;00m parser\n",
      "File \u001B[1;32mc:\\Users\\dalex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:932\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m    929\u001B[0m     \u001B[39mself\u001B[39m\u001B[39m.\u001B[39moptions[\u001B[39m\"\u001B[39m\u001B[39mhas_index_names\u001B[39m\u001B[39m\"\u001B[39m] \u001B[39m=\u001B[39m kwds[\u001B[39m\"\u001B[39m\u001B[39mhas_index_names\u001B[39m\u001B[39m\"\u001B[39m]\n\u001B[0;32m    931\u001B[0m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mhandles: IOHandles \u001B[39m|\u001B[39m \u001B[39mNone\u001B[39;00m \u001B[39m=\u001B[39m \u001B[39mNone\u001B[39;00m\n\u001B[1;32m--> 932\u001B[0m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_engine \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_make_engine(f, \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mengine)\n",
      "File \u001B[1;32mc:\\Users\\dalex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1216\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[1;34m(self, f, engine)\u001B[0m\n\u001B[0;32m   1212\u001B[0m     mode \u001B[39m=\u001B[39m \u001B[39m\"\u001B[39m\u001B[39mrb\u001B[39m\u001B[39m\"\u001B[39m\n\u001B[0;32m   1213\u001B[0m \u001B[39m# error: No overload variant of \"get_handle\" matches argument types\u001B[39;00m\n\u001B[0;32m   1214\u001B[0m \u001B[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001B[39;00m\n\u001B[0;32m   1215\u001B[0m \u001B[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001B[39;00m\n\u001B[1;32m-> 1216\u001B[0m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mhandles \u001B[39m=\u001B[39m get_handle(  \u001B[39m# type: ignore[call-overload]\u001B[39;49;00m\n\u001B[0;32m   1217\u001B[0m     f,\n\u001B[0;32m   1218\u001B[0m     mode,\n\u001B[0;32m   1219\u001B[0m     encoding\u001B[39m=\u001B[39;49m\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49moptions\u001B[39m.\u001B[39;49mget(\u001B[39m\"\u001B[39;49m\u001B[39mencoding\u001B[39;49m\u001B[39m\"\u001B[39;49m, \u001B[39mNone\u001B[39;49;00m),\n\u001B[0;32m   1220\u001B[0m     compression\u001B[39m=\u001B[39;49m\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49moptions\u001B[39m.\u001B[39;49mget(\u001B[39m\"\u001B[39;49m\u001B[39mcompression\u001B[39;49m\u001B[39m\"\u001B[39;49m, \u001B[39mNone\u001B[39;49;00m),\n\u001B[0;32m   1221\u001B[0m     memory_map\u001B[39m=\u001B[39;49m\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49moptions\u001B[39m.\u001B[39;49mget(\u001B[39m\"\u001B[39;49m\u001B[39mmemory_map\u001B[39;49m\u001B[39m\"\u001B[39;49m, \u001B[39mFalse\u001B[39;49;00m),\n\u001B[0;32m   1222\u001B[0m     is_text\u001B[39m=\u001B[39;49mis_text,\n\u001B[0;32m   1223\u001B[0m     errors\u001B[39m=\u001B[39;49m\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49moptions\u001B[39m.\u001B[39;49mget(\u001B[39m\"\u001B[39;49m\u001B[39mencoding_errors\u001B[39;49m\u001B[39m\"\u001B[39;49m, \u001B[39m\"\u001B[39;49m\u001B[39mstrict\u001B[39;49m\u001B[39m\"\u001B[39;49m),\n\u001B[0;32m   1224\u001B[0m     storage_options\u001B[39m=\u001B[39;49m\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49moptions\u001B[39m.\u001B[39;49mget(\u001B[39m\"\u001B[39;49m\u001B[39mstorage_options\u001B[39;49m\u001B[39m\"\u001B[39;49m, \u001B[39mNone\u001B[39;49;00m),\n\u001B[0;32m   1225\u001B[0m )\n\u001B[0;32m   1226\u001B[0m \u001B[39massert\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mhandles \u001B[39mis\u001B[39;00m \u001B[39mnot\u001B[39;00m \u001B[39mNone\u001B[39;00m\n\u001B[0;32m   1227\u001B[0m f \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mhandles\u001B[39m.\u001B[39mhandle\n",
      "File \u001B[1;32mc:\\Users\\dalex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:786\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    781\u001B[0m \u001B[39melif\u001B[39;00m \u001B[39misinstance\u001B[39m(handle, \u001B[39mstr\u001B[39m):\n\u001B[0;32m    782\u001B[0m     \u001B[39m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[0;32m    783\u001B[0m     \u001B[39m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[0;32m    784\u001B[0m     \u001B[39mif\u001B[39;00m ioargs\u001B[39m.\u001B[39mencoding \u001B[39mand\u001B[39;00m \u001B[39m\"\u001B[39m\u001B[39mb\u001B[39m\u001B[39m\"\u001B[39m \u001B[39mnot\u001B[39;00m \u001B[39min\u001B[39;00m ioargs\u001B[39m.\u001B[39mmode:\n\u001B[0;32m    785\u001B[0m         \u001B[39m# Encoding\u001B[39;00m\n\u001B[1;32m--> 786\u001B[0m         handle \u001B[39m=\u001B[39m \u001B[39mopen\u001B[39;49m(\n\u001B[0;32m    787\u001B[0m             handle,\n\u001B[0;32m    788\u001B[0m             ioargs\u001B[39m.\u001B[39;49mmode,\n\u001B[0;32m    789\u001B[0m             encoding\u001B[39m=\u001B[39;49mioargs\u001B[39m.\u001B[39;49mencoding,\n\u001B[0;32m    790\u001B[0m             errors\u001B[39m=\u001B[39;49merrors,\n\u001B[0;32m    791\u001B[0m             newline\u001B[39m=\u001B[39;49m\u001B[39m\"\u001B[39;49m\u001B[39m\"\u001B[39;49m,\n\u001B[0;32m    792\u001B[0m         )\n\u001B[0;32m    793\u001B[0m     \u001B[39melse\u001B[39;00m:\n\u001B[0;32m    794\u001B[0m         \u001B[39m# Binary mode\u001B[39;00m\n\u001B[0;32m    795\u001B[0m         handle \u001B[39m=\u001B[39m \u001B[39mopen\u001B[39m(handle, ioargs\u001B[39m.\u001B[39mmode)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: './data/goodreads_train.csv'"
     ]
    }
   ],
   "source": [
    "if exists(ZIP_PATH):\n",
    "    print('Opening cleaned dataset')\n",
    "    with mgzip.open('mgzip_test.gz', 'rb') as f:\n",
    "        mgzip_df = pickle.load(f)\n",
    "else:\n",
    "    print('Opening original dataset')\n",
    "    reviews_df = pd.read_csv(DS_PATH)\n",
    "    tqdm.pandas()\n",
    "    print('Cleaning reviews')\n",
    "    reviews_df['cleaned_review_text'] = reviews_df['review_text'].progress_apply(lambda x : cleanText(x))\n",
    "    with mgzip.open(ZIP_PATH, 'wb') as f:\n",
    "        pickle.dump(reviews_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_text</th>\n",
       "      <th>date_added</th>\n",
       "      <th>date_updated</th>\n",
       "      <th>read_at</th>\n",
       "      <th>started_at</th>\n",
       "      <th>n_votes</th>\n",
       "      <th>n_comments</th>\n",
       "      <th>cleaned_review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "      <td>18245960</td>\n",
       "      <td>dfdbb7b0eb5a7e4c26d59a937e2e5feb</td>\n",
       "      <td>5</td>\n",
       "      <td>This is a special book. It started slow for ab...</td>\n",
       "      <td>Sun Jul 30 07:44:10 -0700 2017</td>\n",
       "      <td>Wed Aug 30 00:00:26 -0700 2017</td>\n",
       "      <td>Sat Aug 26 12:05:52 -0700 2017</td>\n",
       "      <td>Tue Aug 15 13:23:18 -0700 2017</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>special book start slow first third middl thir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "      <td>16981</td>\n",
       "      <td>a5d2c3628987712d0e05c4f90798eb67</td>\n",
       "      <td>3</td>\n",
       "      <td>Recommended by Don Katz. Avail for free in Dec...</td>\n",
       "      <td>Mon Dec 05 10:46:44 -0800 2016</td>\n",
       "      <td>Wed Mar 22 11:37:04 -0700 2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>recommend katz avail free decemb http www audi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "      <td>28684704</td>\n",
       "      <td>2ede853b14dc4583f96cf5d120af636f</td>\n",
       "      <td>3</td>\n",
       "      <td>A fun, fast paced science fiction thriller. I ...</td>\n",
       "      <td>Tue Nov 15 11:29:22 -0800 2016</td>\n",
       "      <td>Mon Mar 20 23:40:27 -0700 2017</td>\n",
       "      <td>Sat Mar 18 23:22:42 -0700 2017</td>\n",
       "      <td>Fri Mar 17 23:45:40 -0700 2017</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>fun fast pace scienc fiction thriller read nig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "      <td>27161156</td>\n",
       "      <td>ced5675e55cd9d38a524743f5c40996e</td>\n",
       "      <td>0</td>\n",
       "      <td>Recommended reading to understand what is goin...</td>\n",
       "      <td>Wed Nov 09 17:37:04 -0800 2016</td>\n",
       "      <td>Wed Nov 09 17:38:20 -0800 2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>recommend read understand go middl america pos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "      <td>25884323</td>\n",
       "      <td>332732725863131279a8e345b63ac33e</td>\n",
       "      <td>4</td>\n",
       "      <td>I really enjoyed this book, and there is a lot...</td>\n",
       "      <td>Mon Apr 25 09:31:23 -0700 2016</td>\n",
       "      <td>Mon Apr 25 09:31:23 -0700 2016</td>\n",
       "      <td>Sun Jun 26 00:00:00 -0700 2016</td>\n",
       "      <td>Sat May 28 00:00:00 -0700 2016</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>realli enjoy book lot recommend drag littl end...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            user_id   book_id  \\\n",
       "0  8842281e1d1347389f2ab93d60773d4d  18245960   \n",
       "1  8842281e1d1347389f2ab93d60773d4d     16981   \n",
       "2  8842281e1d1347389f2ab93d60773d4d  28684704   \n",
       "3  8842281e1d1347389f2ab93d60773d4d  27161156   \n",
       "4  8842281e1d1347389f2ab93d60773d4d  25884323   \n",
       "\n",
       "                          review_id  rating  \\\n",
       "0  dfdbb7b0eb5a7e4c26d59a937e2e5feb       5   \n",
       "1  a5d2c3628987712d0e05c4f90798eb67       3   \n",
       "2  2ede853b14dc4583f96cf5d120af636f       3   \n",
       "3  ced5675e55cd9d38a524743f5c40996e       0   \n",
       "4  332732725863131279a8e345b63ac33e       4   \n",
       "\n",
       "                                         review_text  \\\n",
       "0  This is a special book. It started slow for ab...   \n",
       "1  Recommended by Don Katz. Avail for free in Dec...   \n",
       "2  A fun, fast paced science fiction thriller. I ...   \n",
       "3  Recommended reading to understand what is goin...   \n",
       "4  I really enjoyed this book, and there is a lot...   \n",
       "\n",
       "                       date_added                    date_updated  \\\n",
       "0  Sun Jul 30 07:44:10 -0700 2017  Wed Aug 30 00:00:26 -0700 2017   \n",
       "1  Mon Dec 05 10:46:44 -0800 2016  Wed Mar 22 11:37:04 -0700 2017   \n",
       "2  Tue Nov 15 11:29:22 -0800 2016  Mon Mar 20 23:40:27 -0700 2017   \n",
       "3  Wed Nov 09 17:37:04 -0800 2016  Wed Nov 09 17:38:20 -0800 2016   \n",
       "4  Mon Apr 25 09:31:23 -0700 2016  Mon Apr 25 09:31:23 -0700 2016   \n",
       "\n",
       "                          read_at                      started_at  n_votes  \\\n",
       "0  Sat Aug 26 12:05:52 -0700 2017  Tue Aug 15 13:23:18 -0700 2017       28   \n",
       "1                             NaN                             NaN        1   \n",
       "2  Sat Mar 18 23:22:42 -0700 2017  Fri Mar 17 23:45:40 -0700 2017       22   \n",
       "3                             NaN                             NaN        5   \n",
       "4  Sun Jun 26 00:00:00 -0700 2016  Sat May 28 00:00:00 -0700 2016        9   \n",
       "\n",
       "   n_comments                                cleaned_review_text  \n",
       "0           1  special book start slow first third middl thir...  \n",
       "1           0  recommend katz avail free decemb http www audi...  \n",
       "2           0  fun fast pace scienc fiction thriller read nig...  \n",
       "3           1  recommend read understand go middl america pos...  \n",
       "4           1  realli enjoy book lot recommend drag littl end...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(reviews_df))\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a special book. It started slow for about the first third, then in the middle third it started to get interesting, then the last third blew my mind. This is what I love about good science fiction - it pushes your thinking about where things can go. \\n It is a 2015 Hugo winner, and translated from its original Chinese, which made it interesting in just a different way from most things I\\'ve read. For instance the intermixing of Chinese revolutionary history - how they kept accusing people of being \"reactionaries\", etc. \\n It is a book about science, and aliens. The science described in the book is impressive - its a book grounded in physics and pretty accurate as far as I could tell. (view spoiler)[Though when it got to folding protons into 8 dimensions I think he was just making stuff up - interesting to think about though. \\n But what would happen if our SETI stations received a message - if we found someone was out there - and the person monitoring and answering the signal on our side was disillusioned? That part of the book was a bit dark - I would like to think human reaction to discovering alien civilization that is hostile would be more like Enders Game where we would band together. \\n I did like how the book unveiled the Trisolaran culture through the game. It was a smart way to build empathy with them and also understand what they\\'ve gone through across so many centuries. And who know a 3 body problem was an unsolvable math problem? But I still don\\'t get who made the game - maybe that will come in the next book. \\n I loved this quote: \\n \"In the long history of scientific progress, how many protons have been smashed apart in accelerators by physicists? How many neutrons and electrons? Probably no fewer than a hundred million. Every collision was probably the end of the civilizations and intelligences in a microcosmos. In fact, even in nature, the destruction of universes must be happening at every second--for example, through the decay of neutrons. Also, a high-energy cosmic ray entering the atmosphere may destroy thousands of such miniature universes....\" \\n (hide spoiler)]'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.loc[0, 'review_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'special book start slow first third middl third start get interest last third blew mind love good scienc fiction push think thing go hugo winner translat origin chines made interest differ way thing read instanc intermix chines revolutionari histori kept accus peopl reactionari etc book scienc alien scienc describ book impress book ground physic pretti accur far could tell view spoiler though got fold proton dimens think make stuff interest think though would happen seti station receiv messag found someon person monitor answer signal side disillus part book bit dark would like think human reaction discov alien civil hostil would like ender game would band togeth like book unveil trisolaran cultur game smart way build empathi also understand gone across mani centuri know bodi problem unsolv math problem still get made game mayb come next book love quot long histori scientif progress mani proton smash apart acceler physicist mani neutron electron probabl fewer hundr million everi collis probabl end civil intellig microcosmo fact even natur destruct univers must happen everi second exampl decay neutron also high energi cosmic ray enter atmospher may destroy thousand miniatur univers hide spoiler'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.loc[0, 'cleaned_review_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "text = \"This is a special book. It started slow for about the first third, then in the middle third it started to get interesting, then the last third blew my mind. This is what I love about good science fiction - it pushes your thinking about where things can go. \\n It is a 2015 Hugo winner, and translated from its original Chinese, which made it interesting in just a different way from most things I\\'ve read.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ex = re.sub('[^a-zA-Z]', ' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a special book  It started slow for about the first third  then in the middle third it started to get interesting  then the last third blew my mind  This is what I love about good science fiction   it pushes your thinking about where things can go    It is a      Hugo winner  and translated from its original Chinese  which made it interesting in just a different way from most things I ve read '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f470148014dc7551fd572c9334044f9c7ea7cc9582f44f15b78776449094e3e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}